{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.2.0-rc2\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "print('TensorFlow:', tf.__version__)\n",
    "np.random.seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFrecordWriter:\n",
    "\n",
    "    def __init__(self, n_samples, n_shards, output_dir='', prefix=''):\n",
    "        self.n_samples = n_samples\n",
    "        self.n_shards = n_shards\n",
    "        self._step_size = self.n_samples // self.n_shards + 1\n",
    "        self.prefix = prefix\n",
    "        self.output_dir = output_dir\n",
    "        self._buffer = []\n",
    "        self._file_count = 1\n",
    "\n",
    "    def _make_example(self, image, boxes, classes):\n",
    "        feature = {\n",
    "            'image':\n",
    "                tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),\n",
    "            'xmins':\n",
    "                tf.train.Feature(float_list=tf.train.FloatList(value=boxes[:, 0])),\n",
    "            'ymins':\n",
    "                tf.train.Feature(float_list=tf.train.FloatList(value=boxes[:, 1])),\n",
    "            'xmaxs':\n",
    "                tf.train.Feature(float_list=tf.train.FloatList(value=boxes[:, 2])),\n",
    "            'ymaxs':\n",
    "                tf.train.Feature(float_list=tf.train.FloatList(value=boxes[:, 3])),\n",
    "            'classes':\n",
    "                tf.train.Feature(int64_list=tf.train.Int64List(value=classes))\n",
    "        }\n",
    "        return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "    def _write_tfrecord(self, tfrecord_path):\n",
    "        print('writing {} samples in {}'.format(len(self._buffer),\n",
    "                                                tfrecord_path))\n",
    "        with tf.io.TFRecordWriter(tfrecord_path) as writer:\n",
    "            for (image, boxes, classes) in self._buffer:\n",
    "                example = self._make_example(image, boxes, classes)\n",
    "                writer.write(example.SerializeToString())\n",
    "\n",
    "    def push(self, image, boxes, classes):\n",
    "        self._buffer.append([image, boxes, classes])\n",
    "        if len(self._buffer) == self._step_size:\n",
    "            fname = self.prefix + '_000' + str(self._file_count) + '.tfrecord'\n",
    "            tfrecord_path = os.path.join(self.output_dir, fname)\n",
    "            self._write_tfrecord(tfrecord_path)\n",
    "            self._clear_buffer()\n",
    "            self._file_count += 1\n",
    "\n",
    "    def flush_last(self):\n",
    "        if len(self._buffer):\n",
    "            fname = self.prefix + '_000' + str(self._file_count) + '.tfrecord'\n",
    "            tfrecord_path = os.path.join(self.output_dir, fname)\n",
    "            self._write_tfrecord(tfrecord_path)\n",
    "\n",
    "    def _clear_buffer(self):\n",
    "        self._buffer = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images\n"
     ]
    }
   ],
   "source": [
    "shapes_dataset_dir = '../tutorials/data/shapes_dataset/'\n",
    "with open(shapes_dataset_dir + 'dataset.json', 'r') as fp:\n",
    "    dataset_json = json.load(fp)\n",
    "\n",
    "all_image_names = list(dataset_json.keys())\n",
    "print('Found {} images'.format(len(all_image_names)))\n",
    "\n",
    "class_map = {'circle': 0, 'rectangle': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4cfaadf0e3462c9035b4bf134b59ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sum_image = []\n",
    "for image_path in tqdm(all_image_names):\n",
    "    image = tf.io.read_file(shapes_dataset_dir + 'images/' + image_path)\n",
    "    image = tf.image.decode_image(image)\n",
    "    sum_image.append(image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 448, 448, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_image = np.array(sum_image)\n",
    "np_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([235.16132109, 235.00810276, 235.0938025 ])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np_image, (0, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([68.30292656, 68.54383801, 68.40923567])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(np_image, (0, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset into 10000 training images and 2500 validation images\n"
     ]
    }
   ],
   "source": [
    "aindices = np.arange(len(all_image_names))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_image_names = all_image_names[:10000]\n",
    "val_image_names = all_image_names[10000:]\n",
    "\n",
    "print('Splitting dataset into {} training images and {} validation images'.format(len(train_image_names), len(val_image_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shards = 8\n",
    "tf_record_dir = '../tutorials/data/shapes_dataset_tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 1251 samples in ../tutorials/data/shapes_dataset_tfrecords/train_0001.tfrecord\n",
      "writing 1251 samples in ../tutorials/data/shapes_dataset_tfrecords/train_0002.tfrecord\n",
      "writing 1251 samples in ../tutorials/data/shapes_dataset_tfrecords/train_0003.tfrecord\n",
      "writing 1251 samples in ../tutorials/data/shapes_dataset_tfrecords/train_0004.tfrecord\n",
      "writing 1251 samples in ../tutorials/data/shapes_dataset_tfrecords/train_0005.tfrecord\n",
      "writing 1251 samples in ../tutorials/data/shapes_dataset_tfrecords/train_0006.tfrecord\n",
      "writing 1251 samples in ../tutorials/data/shapes_dataset_tfrecords/train_0007.tfrecord\n",
      "writing 1243 samples in ../tutorials/data/shapes_dataset_tfrecords/train_0008.tfrecord\n"
     ]
    }
   ],
   "source": [
    "train_tf_record_writer = TFrecordWriter(n_samples=len(train_image_names),\n",
    "                                        n_shards=n_shards,\n",
    "                                        output_dir=tf_record_dir,\n",
    "                                        prefix='train')\n",
    "\n",
    "for image_name in train_image_names:\n",
    "    boxes = []\n",
    "    classes = []\n",
    "\n",
    "    with tf.io.gfile.GFile(shapes_dataset_dir + 'images/' + image_name, 'rb') as fp:\n",
    "        image = fp.read()\n",
    "    \n",
    "    for obj in dataset_json[image_name]:\n",
    "        boxes.append(obj['box'])\n",
    "        classes.append(class_map[obj['category']])\n",
    "    train_tf_record_writer.push(image, np.array(boxes, dtype=np.float32), np.array(classes, dtype=np.int32))\n",
    "train_tf_record_writer.flush_last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 313 samples in ../tutorials/data/shapes_dataset_tfrecords/val_0001.tfrecord\n",
      "writing 313 samples in ../tutorials/data/shapes_dataset_tfrecords/val_0002.tfrecord\n",
      "writing 313 samples in ../tutorials/data/shapes_dataset_tfrecords/val_0003.tfrecord\n",
      "writing 313 samples in ../tutorials/data/shapes_dataset_tfrecords/val_0004.tfrecord\n",
      "writing 313 samples in ../tutorials/data/shapes_dataset_tfrecords/val_0005.tfrecord\n",
      "writing 313 samples in ../tutorials/data/shapes_dataset_tfrecords/val_0006.tfrecord\n",
      "writing 313 samples in ../tutorials/data/shapes_dataset_tfrecords/val_0007.tfrecord\n",
      "writing 309 samples in ../tutorials/data/shapes_dataset_tfrecords/val_0008.tfrecord\n"
     ]
    }
   ],
   "source": [
    "val_tf_record_writer = TFrecordWriter(n_samples=len(val_image_names),\n",
    "                                        n_shards=n_shards,\n",
    "                                        output_dir=tf_record_dir,\n",
    "                                        prefix='val')\n",
    "\n",
    "for image_name in val_image_names:\n",
    "    boxes = []\n",
    "    classes = []\n",
    "\n",
    "    with tf.io.gfile.GFile(shapes_dataset_dir + 'images/' + image_name, 'rb') as fp:\n",
    "        image = fp.read()\n",
    "    \n",
    "    for obj in dataset_json[image_name]:\n",
    "        boxes.append(obj['box'])\n",
    "        classes.append(class_map[obj['category']])\n",
    "    val_tf_record_writer.push(image, np.array(boxes, dtype=np.float32), np.array(classes, dtype=np.int32))\n",
    "val_tf_record_writer.flush_last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
